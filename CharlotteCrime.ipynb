{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all libraries possibly needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime \n",
    "from datetime import datetime as dt\n",
    "from geopy.distance import vincenty # requires separate install - pip install geopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Imports for Classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB #Naive Bayes Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Split Training and Testing Set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Generate Classification Performance Results\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Import imputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# statistic analysis\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the data with `read_csv()`\n",
    "Charlotte_11_15_data = pd.read_csv(\"Datasets/Charlotte-Mecklenburg_2011-2015.csv\", header = 0)\n",
    "Charlotte_16_data = pd.read_csv(\"Datasets/Charlotte-Mecklenburg_2016.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define number of classes\n",
    "NUM_OF_CLASS = 5\n",
    "\n",
    "# interval values to retrieve crime rate from crime rate classes\n",
    "interval_vcr = max(Charlotte_11_15_data['Violent_Crime_Rate_Log2']) / NUM_OF_CLASS + 0.000001\n",
    "interval_pcr = max(Charlotte_11_15_data['Property_Crime_Rate_Log2']) / NUM_OF_CLASS + 0.000001\n",
    "\n",
    "# add columns for classes\n",
    "Charlotte_11_15_data['Violent_Crime_Rate_Class'] = 0\n",
    "Charlotte_11_15_data['Property_Crime_Rate_Class'] = 0\n",
    "\n",
    "\n",
    "for index, row in Charlotte_11_15_data.iterrows():\n",
    "    if(row['Violent_Crime_Rate'] != -1):\n",
    "        Charlotte_11_15_data.at[index, 'Violent_Crime_Rate_Class'] = int(Charlotte_11_15_data.at[index, 'Violent_Crime_Rate_Log2'] / interval_vcr)\n",
    "    else:\n",
    "        Charlotte_11_15_data.at[index, 'Violent_Crime_Rate_Class'] = -1\n",
    "      \n",
    "    if(row['Property_Crime_Rate'] != -1):\n",
    "        Charlotte_11_15_data.at[index, 'Property_Crime_Rate_Class'] = int(Charlotte_11_15_data.at[index, 'Property_Crime_Rate_Log2'] / interval_pcr)\n",
    "    else:\n",
    "        Charlotte_11_15_data.at[index, 'Property_Crime_Rate_Class'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See what the data is like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'NPA', u'Vacant_Land', u'Vacant_Land_Area', u'Commercial_Construction',\n",
      "       u'Commercial_Construction_Permitted_Units', u'Commercial_Size',\n",
      "       u'Commercial_Size_Total', u'Commercial_Building_Age',\n",
      "       u'Impervious_Surface', u'Impervious_Surface_Area', u'Adopt_a_Stream',\n",
      "       u'Adopt_a_Stream_Length', u'Pharmacy_Proximity',\n",
      "       u'Pharmacy_Proximate_Units', u'Housing_Density', u'Housing_Units',\n",
      "       u'Single_Family_Housing', u'Single_Family_Units', u'Housing_Size',\n",
      "       u'Housing_Age', u'New_Residential', u'New_Residential_Permit_Units',\n",
      "       u'Residential_Renovation', u'Residential_Renovation_Permit_Units',\n",
      "       u'Foreclosures', u'Foreclosed_Units', u'Housing_Violations',\n",
      "       u'Housing_Violations_Total', u'Street_Connectivity',\n",
      "       u'Transit_Proximity', u'Transit_Proximate_Units', u'Violent_Crime_Rate',\n",
      "       u'Property_Crime_Rate', u'Combined_Crime_Rate',\n",
      "       u'Violent_Crime_Rate_Log2', u'Property_Crime_Rate_Log2',\n",
      "       u'Combined_Crime_Rate_Log2', u'Violent_Crime_Rate_Class',\n",
      "       u'Property_Crime_Rate_Class'],\n",
      "      dtype='object')\n",
      "(1386, 39)\n",
      "[-1  0  1  2  3  4]\n",
      "[-1  0  1  2  3  4]\n"
     ]
    }
   ],
   "source": [
    "# Get the keys of the `digits` data\n",
    "print(Charlotte_11_15_data.keys())\n",
    "\n",
    "# 1386 rows, 37 cols\n",
    "print(Charlotte_11_15_data.shape)\n",
    "\n",
    "# violent crime rate class\n",
    "Charlotte_11_15_data_Violent_Crime_Rate_Class = Charlotte_11_15_data.Violent_Crime_Rate_Class\n",
    "print((np.unique(Charlotte_11_15_data_Violent_Crime_Rate_Class)))\n",
    "\n",
    "# property crime rate class\n",
    "Charlotte_11_15_data_data_Property_Crime_Rate_Class = Charlotte_11_15_data.Property_Crime_Rate_Class\n",
    "print((np.unique(Charlotte_11_15_data_data_Property_Crime_Rate_Class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'NPA', u'Vacant_Land', u'Vacant_Land_Area', u'Commercial_Construction',\n",
      "       u'Commercial_Construction_Permitted_Units', u'Commercial_Size',\n",
      "       u'Commercial_Size_Total', u'Commercial_Building_Age',\n",
      "       u'Impervious_Surface', u'Impervious_Surface_Area', u'Adopt_a_Stream',\n",
      "       u'Adopt_a_Stream_Length', u'Pharmacy_Proximity',\n",
      "       u'Pharmacy_Proximate_Units', u'Housing_Density', u'Housing_Units',\n",
      "       u'Single_Family_Housing', u'Single_Family_Units', u'Housing_Size',\n",
      "       u'Housing_Age', u'New_Residential', u'New_Residential_Permit_Units',\n",
      "       u'Residential_Renovation', u'Residential_Renovation_Permit_Units',\n",
      "       u'Foreclosures', u'Foreclosed_Units', u'Housing_Violations',\n",
      "       u'Housing_Violations_Total', u'Street_Connectivity',\n",
      "       u'Transit_Proximity', u'Transit_Proximate_Units'],\n",
      "      dtype='object')\n",
      "(462, 31)\n"
     ]
    }
   ],
   "source": [
    "# Get the keys of the `digits` data\n",
    "print(Charlotte_16_data.keys())\n",
    "\n",
    "# 462 rows, 31 cols\n",
    "print(Charlotte_16_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change -1 to NaN in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/handle-missing-data-python/\n",
    "\n",
    "# replace missing values with NaN\n",
    "Charlotte_11_15_data[:] = Charlotte_11_15_data[:].replace(-1, np.NaN)\n",
    "\n",
    "Charlotte_16_data[:] = Charlotte_16_data[:].replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we simply ignore missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we simply drop missing values\n",
    "Charlotte_11_15_data_trimmed = Charlotte_11_15_data.copy(deep=True)\n",
    "Charlotte_16_data_trimmed = Charlotte_16_data.copy(deep=True)\n",
    "\n",
    "Charlotte_11_15_data_trimmed.dropna(inplace=True, how='any')\n",
    "Charlotte_16_data_trimmed.dropna(inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 14 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.23      0.39      0.29        80\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "        2.0       0.58      0.20      0.30       141\n",
      "        3.0       0.00      0.00      0.00        29\n",
      "        4.0       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.39      0.23      0.25       257\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.79      0.77       127\n",
      "        1.0       0.15      0.36      0.22        22\n",
      "        2.0       0.54      0.37      0.44        70\n",
      "        3.0       0.50      0.33      0.40        36\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.61      0.57      0.58       257\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 15 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.81      0.79       125\n",
      "        1.0       0.48      0.35      0.40        72\n",
      "        2.0       0.52      0.57      0.54        44\n",
      "        3.0       0.38      0.56      0.45        16\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.62      0.62      0.62       257\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.66      0.63      0.64       139\n",
      "        1.0       0.23      0.24      0.24        50\n",
      "        2.0       0.35      0.34      0.35        50\n",
      "        3.0       0.21      0.28      0.24        18\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.48      0.47      0.48       257\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.667951188182\n"
     ]
    }
   ],
   "source": [
    "# only Violent Crime Rate\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_trimmed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_trimmed.loc[:,['Violent_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_vcr = MLPClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_vcr = GaussianNB().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_vcr = DecisionTreeClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_vcr, c_train_vcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 22 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       0.79      0.53      0.64       133\n",
      "        2.0       0.61      0.71      0.66       124\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.70      0.62      0.65       257\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 2 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.20      0.08      0.11        13\n",
      "        1.0       0.77      0.43      0.55       159\n",
      "        2.0       0.27      0.78      0.40        50\n",
      "        3.0       0.59      0.29      0.38        35\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.62      0.46      0.48       257\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 14 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         4\n",
      "        1.0       0.69      0.71      0.70        87\n",
      "        2.0       0.81      0.83      0.82       139\n",
      "        3.0       0.88      0.60      0.71        25\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.75      0.75      0.75       257\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 6 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       0.66      0.60      0.63        98\n",
      "        2.0       0.72      0.72      0.72       144\n",
      "        3.0       0.18      0.20      0.19        15\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.66      0.64      0.65       257\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.71403893429\n"
     ]
    }
   ],
   "source": [
    "# only Property Crime Rate\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_trimmed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_trimmed.loc[:,['Property_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_pcr = MLPClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_pcr = GaussianNB().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_pcr = DecisionTreeClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_pcr, c_train_pcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the size of training dataset to build a better model\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_trimmed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_trimmed.loc[:,['Violent_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_trimmed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_trimmed.loc[:,['Property_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "\n",
    "# predict crime rate besed on best classifier from above\n",
    "c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(Charlotte_16_data_trimmed)\n",
    "c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(Charlotte_16_data_trimmed)\n",
    "\n",
    "Charlotte_16_data_write2csv = Charlotte_16_data_trimmed.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Combined_Crime_Rate'] = 0.0\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Log2'] = Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] * interval_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Log2'] = Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] * interval_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate'] = pow(Charlotte_16_data_write2csv['Violent_Crime_Rate_Log2'], 2.0)\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate'] = pow(Charlotte_16_data_write2csv['Property_Crime_Rate_Log2'], 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reorder columns to keep consistent with 11-15 csv file\n",
    "Charlotte_16_data_write2csv['vcr_temp'] = Charlotte_16_data_write2csv['Violent_Crime_Rate']\n",
    "Charlotte_16_data_write2csv['pcr_temp'] = Charlotte_16_data_write2csv['Property_Crime_Rate']\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate'] = Charlotte_16_data_write2csv['Violent_Crime_Rate_Class']\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate'] = Charlotte_16_data_write2csv['Property_Crime_Rate_Class']\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] = Charlotte_16_data_write2csv['vcr_temp']\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] = Charlotte_16_data_write2csv['pcr_temp']\n",
    "\n",
    "Charlotte_16_data_write2csv.drop('vcr_temp', axis=1, inplace=True)\n",
    "Charlotte_16_data_write2csv.drop('pcr_temp', axis=1, inplace=True)\n",
    "\n",
    "# Don't forget to rename columns!\n",
    "Charlotte_16_data_write2csv.rename(columns={'Violent_Crime_Rate_Class': 'newName1', 'Property_Crime_Rate_Class': 'newName2'}, inplace=True)\n",
    "Charlotte_16_data_write2csv.rename(columns={'Violent_Crime_Rate': 'Violent_Crime_Rate_Class', 'Property_Crime_Rate': 'Property_Crime_Rate_Class'}, inplace=True)\n",
    "Charlotte_16_data_write2csv.rename(columns={'newName1':'Violent_Crime_Rate', 'newName2':'Property_Crime_Rate'}, inplace=True)\n",
    "\n",
    "for index, row in Charlotte_16_data_write2csv.iterrows():\n",
    "    Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = (Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] + Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate']) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "Charlotte_16_data_write2csv.to_csv(\"Datasets/Charlotte-Mecklenburg_2016_predict_IGNORE.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar charts based on predicted data for 2016\n",
    "c_predict_2016_vcr = c_predict_vcr.astype(int)\n",
    "c_predict_2016_pcr = c_predict_pcr.astype(int)\n",
    "\n",
    "count_vcr_2016 = np.bincount(c_predict_2016_vcr)\n",
    "count_pcr_2016 = np.bincount(c_predict_2016_pcr)\n",
    "\n",
    "# print c_predict_2016_vcr\n",
    "# print c_predict_2016_pcr\n",
    "\n",
    "# Count # of class predictions \n",
    "count_class_0_vcr_2016 = count_vcr_2016[0]\n",
    "count_class_1_vcr_2016 = count_vcr_2016[1]\n",
    "count_class_2_vcr_2016 = count_vcr_2016[2]\n",
    "count_class_3_vcr_2016 = count_vcr_2016[3]\n",
    "\n",
    "count_class_0_pcr_2016 = count_pcr_2016[0]\n",
    "count_class_1_pcr_2016 = count_pcr_2016[1]\n",
    "count_class_2_pcr_2016 = count_pcr_2016[2]\n",
    "count_class_3_pcr_2016 = count_pcr_2016[3]\n",
    "\n",
    "# Define Classes Names\n",
    "#objects = (\"Class 0: \" + str(count_class_0_vcr_2016), 'Class 1', 'Class 2', 'Class 3')\n",
    "objects = ('Lower Crime', '', '', 'Higher Crime')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "# Plotting Violent Crime Data 2016\n",
    "performance = [count_class_0_vcr_2016, count_class_1_vcr_2016, count_class_2_vcr_2016, count_class_3_vcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Violent Crime')\n",
    "plt.title('Violent Crime Data 2016 - Ignore')\n",
    "plt.savefig('Barcharts/Violent_Crime_Data_2016_IGNORE.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Property Crime Data 2016\n",
    "performance = [count_class_0_pcr_2016, count_class_1_pcr_2016, count_class_2_pcr_2016, count_class_3_pcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Property Crime')\n",
    "plt.title('Property Crime Data 2016 - Ignore')\n",
    "plt.savefig('Barcharts/Property_Crime_Data_2016_IGNORE.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we impute missing values\n",
    "\n",
    "# I. Assign fixed value to missing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing missing values with -1\n",
    "Charlotte_11_15_data_fixed = Charlotte_11_15_data.copy(deep=True)\n",
    "Charlotte_16_data_fixed = Charlotte_16_data.copy(deep=True)\n",
    "\n",
    "Charlotte_11_15_data_fixed.fillna(10, inplace = True)\n",
    "Charlotte_16_data_fixed.fillna(10, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 61 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.00      0.00      0.00         7\n",
      "        0.0       0.48      0.66      0.56       157\n",
      "        1.0       0.31      0.22      0.26       149\n",
      "        2.0       0.45      0.27      0.34       145\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.41      0.38      0.38       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.12      0.08      0.10        25\n",
      "        0.0       0.74      0.75      0.75       213\n",
      "        1.0       0.10      0.37      0.16        30\n",
      "        2.0       0.43      0.42      0.42        88\n",
      "        3.0       0.77      0.24      0.37        96\n",
      "        4.0       1.00      0.50      0.67         6\n",
      "\n",
      "avg / total       0.61      0.52      0.53       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 16 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.65      0.46      0.54        24\n",
      "        0.0       0.77      0.80      0.79       209\n",
      "        1.0       0.30      0.34      0.32        95\n",
      "        2.0       0.46      0.40      0.43       100\n",
      "        3.0       0.30      0.33      0.32        27\n",
      "        4.0       0.67      0.67      0.67         3\n",
      "\n",
      "avg / total       0.57      0.57      0.57       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.18      0.25      0.21        12\n",
      "        0.0       0.83      0.61      0.71       293\n",
      "        1.0       0.25      0.39      0.30        67\n",
      "        2.0       0.37      0.44      0.40        72\n",
      "        3.0       0.13      0.29      0.18        14\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.64      0.53      0.57       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.635776177054\n"
     ]
    }
   ],
   "source": [
    "# only Violent Crime Rate\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_fixed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_fixed.loc[:,['Violent_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_vcr = MLPClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_vcr = GaussianNB().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_vcr = DecisionTreeClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_vcr, c_train_vcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 25 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.00      0.00      0.00         0\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       0.30      0.60      0.40        83\n",
      "        2.0       0.92      0.54      0.68       374\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.80      0.55      0.63       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.17      0.30      0.21        10\n",
      "        0.0       0.48      0.08      0.14       123\n",
      "        1.0       0.54      0.48      0.51       186\n",
      "        2.0       0.25      0.75      0.38        75\n",
      "        3.0       0.70      0.33      0.45        63\n",
      "        4.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.49      0.39      0.37       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 16 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.39      0.37      0.38        19\n",
      "        0.0       0.33      0.28      0.30        25\n",
      "        1.0       0.65      0.71      0.68       152\n",
      "        2.0       0.79      0.75      0.77       233\n",
      "        3.0       0.67      0.69      0.68        29\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.69      0.69      0.69       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.00      0.00      0.00         0\n",
      "        0.0       0.19      0.40      0.26        10\n",
      "        1.0       0.62      0.56      0.59       186\n",
      "        2.0       0.71      0.63      0.67       249\n",
      "        3.0       0.10      0.23      0.14        13\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.65      0.58      0.61       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.69399032606\n"
     ]
    }
   ],
   "source": [
    "# only Property Crime Rate\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_fixed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_fixed.loc[:,['Property_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_pcr = MLPClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_pcr = GaussianNB().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_pcr = DecisionTreeClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_pcr, c_train_pcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the size of training dataset to build a better model\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_fixed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_fixed.loc[:,['Violent_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_fixed.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_fixed.loc[:,['Property_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "\n",
    "# predict crime rate besed on best classifier from above\n",
    "c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(Charlotte_16_data_fixed)\n",
    "c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(Charlotte_16_data_fixed)\n",
    "\n",
    "Charlotte_16_data_write2csv = Charlotte_16_data_fixed.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Charlotte_16_data_write2csv['Violent_Crime_Rate'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Combined_Crime_Rate'] = 0.0\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Log2'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Log2'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] = c_predict_pcr\n",
    "\n",
    "for index, row in Charlotte_16_data_write2csv.iterrows():\n",
    "    if(row['Violent_Crime_Rate_Class'] != 10):\n",
    "        Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Class'] * interval_vcr\n",
    "        Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'], 2.0)\n",
    "        \n",
    "    if(row['Property_Crime_Rate_Class'] != 10):\n",
    "        Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Class'] * interval_vcr\n",
    "        Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'], 2.0)\n",
    "\n",
    "for index, row in Charlotte_16_data_write2csv.iterrows():\n",
    "    if(row['Violent_Crime_Rate'] != 10 and row['Property_Crime_Rate'] != 10):\n",
    "        Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = (Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] + Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate']) / 2.0\n",
    "    elif (row['Violent_Crime_Rate'] != 10):\n",
    "        Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate']\n",
    "    elif (row['Property_Crime_Rate'] != 10):\n",
    "          Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate']\n",
    "    else:\n",
    "      Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = 10\n",
    "        \n",
    "Charlotte_16_data_write2csv[:] = Charlotte_16_data_write2csv[:].replace(10, np.NaN)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "Charlotte_16_data_write2csv.to_csv(\"Datasets/Charlotte-Mecklenburg_2016_predict_FIXED.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar charts based on predicted data for 2016\n",
    "c_predict_2016_vcr = c_predict_vcr.astype(int)\n",
    "c_predict_2016_pcr = c_predict_pcr.astype(int)\n",
    "\n",
    "count_vcr_2016 = np.bincount(c_predict_2016_vcr)\n",
    "count_pcr_2016 = np.bincount(c_predict_2016_pcr)\n",
    "\n",
    "# print c_predict_2016_vcr\n",
    "# print c_predict_2016_pcr\n",
    "\n",
    "# Count # of class predictions \n",
    "count_class_0_vcr_2016 = count_vcr_2016[0]\n",
    "count_class_1_vcr_2016 = count_vcr_2016[1]\n",
    "count_class_2_vcr_2016 = count_vcr_2016[2]\n",
    "count_class_3_vcr_2016 = count_vcr_2016[3]\n",
    "\n",
    "count_class_0_pcr_2016 = count_pcr_2016[0]\n",
    "count_class_1_pcr_2016 = count_pcr_2016[1]\n",
    "count_class_2_pcr_2016 = count_pcr_2016[2]\n",
    "count_class_3_pcr_2016 = count_pcr_2016[3]\n",
    "\n",
    "# Define Classes Names\n",
    "#objects = (\"Class 0: \" + str(count_class_0_vcr_2016), 'Class 1', 'Class 2', 'Class 3')\n",
    "objects = ('Lower Crime', '', '', 'Higher Crime')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "# Plotting Violent Crime Data 2016\n",
    "performance = [count_class_0_vcr_2016, count_class_1_vcr_2016, count_class_2_vcr_2016, count_class_3_vcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Violent Crime')\n",
    "plt.title('Violent Crime Data 2016 - Fixed')\n",
    "plt.savefig('Barcharts/Violent_Crime_Data_2016_FIXED.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Property Crime Data 2016\n",
    "performance = [count_class_0_pcr_2016, count_class_1_pcr_2016, count_class_2_pcr_2016, count_class_3_pcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Property Crime')\n",
    "plt.title('Property Crime Data 2016 - Fixed')\n",
    "plt.savefig('Barcharts/Property_Crime_Data_2016_FIXED.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Imputer() Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute missing values with means\n",
    "Charlotte_11_15_data_imputed_mean = Charlotte_11_15_data.copy(deep=True)\n",
    "Charlotte_16_data_imputed_mean = Charlotte_16_data.copy(deep=True)\n",
    "\n",
    "cols_11_15 = Charlotte_11_15_data_imputed_mean.columns\n",
    "cols_16 = Charlotte_16_data_imputed_mean.columns\n",
    "\n",
    "imputer_11_15 = Imputer(strategy='mean')\n",
    "Charlotte_11_15_data_imputed_mean = imputer_11_15.fit_transform(Charlotte_11_15_data_imputed_mean)\n",
    "Charlotte_11_15_data_imputed_mean = pd.DataFrame(Charlotte_11_15_data_imputed_mean, columns = cols_11_15)\n",
    "\n",
    "imputer_16 = Imputer(strategy='mean')\n",
    "Charlotte_16_data_imputed_mean = imputer_16.fit_transform(Charlotte_16_data_imputed_mean)\n",
    "Charlotte_16_data_imputed_mean = pd.DataFrame(Charlotte_16_data_imputed_mean, columns = cols_16)\n",
    "\n",
    "# make sure class values are integer\n",
    "for index, row in Charlotte_11_15_data_imputed_mean.iterrows():\n",
    "    Charlotte_11_15_data_imputed_mean.at[index, 'Violent_Crime_Rate_Class'] = int(Charlotte_11_15_data_imputed_mean.at[index, 'Violent_Crime_Rate_Class'])\n",
    "    Charlotte_11_15_data_imputed_mean.at[index, 'Property_Crime_Rate_Class'] = int(Charlotte_11_15_data_imputed_mean.at[index, 'Property_Crime_Rate_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 28 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.54      0.65       395\n",
      "        1.0       0.05      0.06      0.05        63\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.70      0.47      0.57       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 2 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.92      0.79       200\n",
      "        1.0       0.36      0.32      0.34        98\n",
      "        2.0       0.41      0.50      0.45        68\n",
      "        3.0       0.83      0.22      0.35        90\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.61      0.59      0.56       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 16 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.83      0.83       261\n",
      "        1.0       0.41      0.35      0.38       101\n",
      "        2.0       0.48      0.54      0.51        74\n",
      "        3.0       0.33      0.38      0.36        21\n",
      "        4.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.65      0.66      0.65       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 0 ns\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.69      0.75       321\n",
      "        1.0       0.20      0.24      0.22        72\n",
      "        2.0       0.30      0.48      0.37        52\n",
      "        3.0       0.04      0.09      0.06        11\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.65      0.57      0.61       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.676740787139\n"
     ]
    }
   ],
   "source": [
    "# only Violent Crime Rate\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_imputed_mean.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_mean.loc[:,['Violent_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_vcr = MLPClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_vcr = GaussianNB().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_vcr = DecisionTreeClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_vcr, c_train_vcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 52 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.05      0.01      0.02       103\n",
      "        1.0       0.12      0.67      0.20        33\n",
      "        2.0       0.67      0.53      0.59       292\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.45      0.39      0.40       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 1e+03 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.16      0.07      0.10        43\n",
      "        1.0       0.65      0.54      0.59       223\n",
      "        2.0       0.52      0.73      0.61       162\n",
      "        3.0       0.50      0.42      0.46        26\n",
      "        4.0       1.00      0.25      0.40         4\n",
      "\n",
      "avg / total       0.55      0.56      0.54       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 22 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.16      0.16      0.16        19\n",
      "        1.0       0.67      0.68      0.68       183\n",
      "        2.0       0.77      0.76      0.76       234\n",
      "        3.0       0.64      0.78      0.70        18\n",
      "        4.0       1.00      0.25      0.40         4\n",
      "\n",
      "avg / total       0.70      0.70      0.70       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 7 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.05      0.33      0.09         3\n",
      "        1.0       0.65      0.57      0.61       211\n",
      "        2.0       0.64      0.64      0.64       228\n",
      "        3.0       0.09      0.12      0.11        16\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.62      0.59      0.60       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.706886592198\n"
     ]
    }
   ],
   "source": [
    "# only Property Crime Rate\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_imputed_mean.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_mean.loc[:,['Property_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_pcr = MLPClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_pcr = GaussianNB().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_pcr = DecisionTreeClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_pcr, c_train_pcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the size of training dataset to build a better model\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_imputed_mean.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_mean.loc[:,['Violent_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_imputed_mean.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_mean.loc[:,['Property_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "\n",
    "# predict crime rate besed on best classifier from above\n",
    "c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(Charlotte_16_data_imputed_mean)\n",
    "c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(Charlotte_16_data_imputed_mean)\n",
    "\n",
    "Charlotte_16_data_write2csv = Charlotte_16_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Charlotte_16_data_write2csv['Violent_Crime_Rate'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Combined_Crime_Rate'] = 0.0\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Log2'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Log2'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] = c_predict_pcr\n",
    "\n",
    "for index, row in Charlotte_16_data_write2csv.iterrows():\n",
    "    Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Class'] * interval_vcr\n",
    "    Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'], 2.0)\n",
    "        \n",
    "    Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Class'] * interval_vcr\n",
    "    Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'], 2.0)\n",
    "    \n",
    "    Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = (Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] + Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate']) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "Charlotte_16_data_write2csv.to_csv(\"Datasets/Charlotte-Mecklenburg_2016_predict_MEAN.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar charts based on predicted data for 2016\n",
    "c_predict_2016_vcr = c_predict_vcr.astype(int)\n",
    "c_predict_2016_pcr = c_predict_pcr.astype(int)\n",
    "\n",
    "count_vcr_2016 = np.bincount(c_predict_2016_vcr)\n",
    "count_pcr_2016 = np.bincount(c_predict_2016_pcr)\n",
    "\n",
    "# print c_predict_2016_vcr\n",
    "# print c_predict_2016_pcr\n",
    "\n",
    "# Count # of class predictions \n",
    "count_class_0_vcr_2016 = count_vcr_2016[0]\n",
    "count_class_1_vcr_2016 = count_vcr_2016[1]\n",
    "count_class_2_vcr_2016 = count_vcr_2016[2]\n",
    "count_class_3_vcr_2016 = count_vcr_2016[3]\n",
    "\n",
    "count_class_0_pcr_2016 = count_pcr_2016[0]\n",
    "count_class_1_pcr_2016 = count_pcr_2016[1]\n",
    "count_class_2_pcr_2016 = count_pcr_2016[2]\n",
    "count_class_3_pcr_2016 = count_pcr_2016[3]\n",
    "\n",
    "# Define Classes Names\n",
    "#objects = (\"Class 0: \" + str(count_class_0_vcr_2016), 'Class 1', 'Class 2', 'Class 3')\n",
    "objects = ('Lower Crime', '', '', 'Higher Crime')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "# Plotting Violent Crime Data 2016\n",
    "performance = [count_class_0_vcr_2016, count_class_1_vcr_2016, count_class_2_vcr_2016, count_class_3_vcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Violent Crime')\n",
    "plt.title('Violent Crime Data 2016 - Mean')\n",
    "plt.savefig('Barcharts/Violent_Crime_Data_2016_MEAN.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Property Crime Data 2016\n",
    "performance = [count_class_0_pcr_2016, count_class_1_pcr_2016, count_class_2_pcr_2016, count_class_3_pcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Property Crime')\n",
    "plt.title('Property Crime Data 2016 - Mean')\n",
    "plt.savefig('Barcharts/Property_Crime_Data_2016_MEAN.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Imputer() Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute missing values with median\n",
    "Charlotte_11_15_data_imputed_median = Charlotte_11_15_data.copy(deep=True)\n",
    "Charlotte_16_data_imputed_median = Charlotte_16_data.copy(deep=True)\n",
    "\n",
    "cols_11_15 = Charlotte_11_15_data_imputed_median.columns\n",
    "cols_16 = Charlotte_16_data_imputed_median.columns\n",
    "\n",
    "imputer_11_15 = Imputer(strategy='median')\n",
    "Charlotte_11_15_data_imputed_median = imputer_11_15.fit_transform(Charlotte_11_15_data_imputed_median)\n",
    "Charlotte_11_15_data_imputed_median = pd.DataFrame(Charlotte_11_15_data_imputed_median, columns = cols_11_15)\n",
    "\n",
    "imputer_16 = Imputer(strategy='median')\n",
    "Charlotte_16_data_imputed_median = imputer_16.fit_transform(Charlotte_16_data_imputed_median)\n",
    "Charlotte_16_data_imputed_median = pd.DataFrame(Charlotte_16_data_imputed_median, columns = cols_16)\n",
    "\n",
    "# make sure class values are integer\n",
    "for index, row in Charlotte_11_15_data_imputed_median.iterrows():\n",
    "    Charlotte_11_15_data_imputed_median.at[index, 'Violent_Crime_Rate_Class'] = int(Charlotte_11_15_data_imputed_median.at[index, 'Violent_Crime_Rate_Class'])\n",
    "    Charlotte_11_15_data_imputed_median.at[index, 'Property_Crime_Rate_Class'] = int(Charlotte_11_15_data_imputed_median.at[index, 'Property_Crime_Rate_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 46 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.64      0.73       335\n",
      "        1.0       0.08      0.25      0.12        28\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "        3.0       0.62      0.19      0.29        86\n",
      "        4.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.73      0.52      0.59       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 2 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.89      0.80       213\n",
      "        1.0       0.23      0.28      0.25        74\n",
      "        2.0       0.41      0.48      0.44        67\n",
      "        3.0       0.81      0.21      0.34        98\n",
      "        4.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.61      0.57      0.55       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 17 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.83      0.83       258\n",
      "        1.0       0.36      0.35      0.35        94\n",
      "        2.0       0.43      0.48      0.45        71\n",
      "        3.0       0.54      0.42      0.47        33\n",
      "        4.0       0.33      0.50      0.40         2\n",
      "\n",
      "avg / total       0.65      0.65      0.65       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 8 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.64      0.72       335\n",
      "        1.0       0.20      0.34      0.25        53\n",
      "        2.0       0.29      0.46      0.36        50\n",
      "        3.0       0.15      0.29      0.20        14\n",
      "        4.0       0.33      0.17      0.22         6\n",
      "\n",
      "avg / total       0.67      0.57      0.60       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.655144935101\n"
     ]
    }
   ],
   "source": [
    "# only Violent Crime Rate\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_imputed_median.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_median.loc[:,['Violent_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_vcr = MLPClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_vcr = GaussianNB().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_vcr = DecisionTreeClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_vcr, c_train_vcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 41 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.24      0.07      0.11        69\n",
      "        1.0       0.50      0.41      0.45       214\n",
      "        2.0       0.37      0.49      0.42       175\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.41      0.39      0.39       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 1e+03 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.33      0.15      0.20        48\n",
      "        1.0       0.77      0.55      0.64       244\n",
      "        2.0       0.25      0.77      0.38        77\n",
      "        3.0       0.74      0.23      0.35        87\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.63      0.48      0.50       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 20 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.33      0.33      0.33        21\n",
      "        1.0       0.59      0.70      0.64       148\n",
      "        2.0       0.81      0.71      0.76       265\n",
      "        3.0       0.48      0.59      0.53        22\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.70      0.68      0.69       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 7 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.05      0.25      0.08         4\n",
      "        1.0       0.62      0.60      0.61       183\n",
      "        2.0       0.72      0.65      0.68       261\n",
      "        3.0       0.04      0.11      0.06         9\n",
      "        4.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.66      0.61      0.63       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.715513101576\n"
     ]
    }
   ],
   "source": [
    "# only Property Crime Rate\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_imputed_median.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_median.loc[:,['Property_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_pcr = MLPClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_pcr = GaussianNB().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_pcr = DecisionTreeClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_pcr, c_train_pcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the size of training dataset to build a better model\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_imputed_median.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_median.loc[:,['Violent_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_imputed_median.loc[:, ['NPA', 'Vacant_Land', \n",
    "    'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_median.loc[:,['Property_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "\n",
    "# predict crime rate besed on best classifier from above\n",
    "c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(Charlotte_16_data_imputed_median)\n",
    "c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(Charlotte_16_data_imputed_median)\n",
    "\n",
    "Charlotte_16_data_write2csv = Charlotte_16_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Charlotte_16_data_write2csv['Violent_Crime_Rate'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Combined_Crime_Rate'] = 0.0\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Log2'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Log2'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] = c_predict_pcr\n",
    "\n",
    "for index, row in Charlotte_16_data_write2csv.iterrows():\n",
    "    Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Class'] * interval_vcr\n",
    "    Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'], 2.0)\n",
    "        \n",
    "    Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Class'] * interval_vcr\n",
    "    Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'], 2.0)\n",
    "    \n",
    "    Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = (Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] + Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate']) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "Charlotte_16_data_write2csv.to_csv(\"Datasets/Charlotte-Mecklenburg_2016_predict_MEDIAN.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar charts based on predicted data for 2016\n",
    "c_predict_2016_vcr = c_predict_vcr.astype(int)\n",
    "c_predict_2016_pcr = c_predict_pcr.astype(int)\n",
    "\n",
    "count_vcr_2016 = np.bincount(c_predict_2016_vcr)\n",
    "count_pcr_2016 = np.bincount(c_predict_2016_pcr)\n",
    "\n",
    "# print c_predict_2016_vcr\n",
    "# print c_predict_2016_pcr\n",
    "\n",
    "# Count # of class predictions \n",
    "count_class_0_vcr_2016 = count_vcr_2016[0]\n",
    "count_class_1_vcr_2016 = count_vcr_2016[1]\n",
    "count_class_2_vcr_2016 = count_vcr_2016[2]\n",
    "count_class_3_vcr_2016 = count_vcr_2016[3]\n",
    "\n",
    "count_class_0_pcr_2016 = count_pcr_2016[0]\n",
    "count_class_1_pcr_2016 = count_pcr_2016[1]\n",
    "count_class_2_pcr_2016 = count_pcr_2016[2]\n",
    "count_class_3_pcr_2016 = count_pcr_2016[3]\n",
    "\n",
    "# Define Classes Names\n",
    "#objects = (\"Class 0: \" + str(count_class_0_vcr_2016), 'Class 1', 'Class 2', 'Class 3')\n",
    "objects = ('Lower Crime', '', '', 'Higher Crime')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "# Plotting Violent Crime Data 2016\n",
    "performance = [count_class_0_vcr_2016, count_class_1_vcr_2016, count_class_2_vcr_2016, count_class_3_vcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Violent Crime')\n",
    "plt.title('Violent Crime Data 2016 - Median')\n",
    "plt.savefig('Barcharts/Violent_Crime_Data_2016_MEDIAN.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Property Crime Data 2016\n",
    "performance = [count_class_0_pcr_2016, count_class_1_pcr_2016, count_class_2_pcr_2016, count_class_3_pcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Property Crime')\n",
    "plt.title('Property Crime Data 2016 - Median')\n",
    "plt.savefig('Barcharts/Property_Crime_Data_2016_MEDIAN.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Imputer() Most Frequently Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute missing values with most_frequent\n",
    "Charlotte_11_15_data_imputed_most_frequent = Charlotte_11_15_data.copy(deep=True)\n",
    "Charlotte_16_data_imputed_most_frequent = Charlotte_16_data.copy(deep=True)\n",
    "\n",
    "cols_11_15 = Charlotte_11_15_data_imputed_most_frequent.columns\n",
    "cols_16 = Charlotte_16_data_imputed_most_frequent.columns\n",
    "\n",
    "imputer_11_15 = Imputer(strategy='most_frequent')\n",
    "Charlotte_11_15_data_imputed_most_frequent = imputer_11_15.fit_transform(Charlotte_11_15_data_imputed_most_frequent)\n",
    "Charlotte_11_15_data_imputed_most_frequent = pd.DataFrame(Charlotte_11_15_data_imputed_most_frequent, columns = cols_11_15)\n",
    "\n",
    "imputer_16 = Imputer(strategy='most_frequent')\n",
    "Charlotte_16_data_imputed_most_frequent = imputer_16.fit_transform(Charlotte_16_data_imputed_most_frequent)\n",
    "Charlotte_16_data_imputed_most_frequent = pd.DataFrame(Charlotte_16_data_imputed_most_frequent, columns = cols_16)\n",
    "\n",
    "# make sure class values are integer\n",
    "for index, row in Charlotte_11_15_data_imputed_most_frequent.iterrows():\n",
    "    Charlotte_11_15_data_imputed_most_frequent.at[index, 'Violent_Crime_Rate_Class'] = int(Charlotte_11_15_data_imputed_most_frequent.at[index, 'Violent_Crime_Rate_Class'])\n",
    "    Charlotte_11_15_data_imputed_most_frequent.at[index, 'Property_Crime_Rate_Class'] = int(Charlotte_11_15_data_imputed_most_frequent.at[index, 'Property_Crime_Rate_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 53 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.53      0.69       458\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "        2.0       0.00      0.00      0.00         0\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.53      0.69       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 1e+03 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.88      0.77       190\n",
      "        1.0       0.26      0.30      0.28        83\n",
      "        2.0       0.53      0.42      0.47       112\n",
      "        3.0       0.62      0.29      0.40        69\n",
      "        4.0       1.00      0.25      0.40         4\n",
      "\n",
      "avg / total       0.57      0.57      0.55       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 18 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.84      0.84       240\n",
      "        1.0       0.46      0.44      0.45       100\n",
      "        2.0       0.45      0.49      0.47        81\n",
      "        3.0       0.44      0.48      0.46        29\n",
      "        4.0       1.00      0.12      0.22         8\n",
      "\n",
      "avg / total       0.66      0.66      0.65       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 6 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.63      0.72       327\n",
      "        1.0       0.19      0.37      0.25        49\n",
      "        2.0       0.33      0.48      0.39        61\n",
      "        3.0       0.28      0.45      0.35        20\n",
      "        4.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.68      0.57      0.61       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.696147823364\n"
     ]
    }
   ],
   "source": [
    "# only Violent Crime Rate\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_imputed_most_frequent.loc[:, ['NPA', \n",
    "    'Vacant_Land', 'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_most_frequent.loc[:,['Violent_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_vcr = MLPClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_vcr = GaussianNB().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_vcr = DecisionTreeClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(f_test_vcr)\n",
    "print(classification_report(c_predict_vcr, c_test_vcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_vcr, c_train_vcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron Classifier\n",
      "Wall time: 153 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.26      0.13      0.17        39\n",
      "        1.0       0.33      0.64      0.44        87\n",
      "        2.0       0.89      0.65      0.75       332\n",
      "        3.0       0.00      0.00      0.00         0\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.73      0.60      0.64       458\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Wall time: 1e+03 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        20\n",
      "        1.0       0.84      0.44      0.58       324\n",
      "        2.0       0.20      0.72      0.32        68\n",
      "        3.0       0.71      0.42      0.53        40\n",
      "        4.0       1.00      0.33      0.50         6\n",
      "\n",
      "avg / total       0.70      0.46      0.51       458\n",
      "\n",
      "Decision Tree Classifier\n",
      "Wall time: 17 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.11      0.22      0.14         9\n",
      "        1.0       0.70      0.66      0.68       181\n",
      "        2.0       0.75      0.76      0.75       242\n",
      "        3.0       0.50      0.60      0.55        20\n",
      "        4.0       1.00      0.33      0.50         6\n",
      "\n",
      "avg / total       0.71      0.69      0.70       458\n",
      "\n",
      "K Nearest Neighbors\n",
      "Wall time: 7 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.16      0.50      0.24         6\n",
      "        1.0       0.59      0.55      0.57       183\n",
      "        2.0       0.68      0.65      0.66       254\n",
      "        3.0       0.12      0.20      0.15        15\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.62      0.59      0.61       458\n",
      "\n",
      "Linear Discriminant Analysis (LDA)\n",
      "0.705800883878\n"
     ]
    }
   ],
   "source": [
    "# only Property Crime Rate\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_imputed_most_frequent.loc[:, ['NPA', \n",
    "    'Vacant_Land', 'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_most_frequent.loc[:,['Property_Crime_Rate_Class']], test_size=0.33, train_size =0.67, shuffle=True)\n",
    "\n",
    "print('Multi-Layer Perceptron Classifier')\n",
    "%time c_predict_pcr = MLPClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Naive Bayes Classifier')\n",
    "%time c_predict_pcr = GaussianNB().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "%time c_predict_pcr = DecisionTreeClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('K Nearest Neighbors')\n",
    "%time c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(f_test_pcr)\n",
    "print(classification_report(c_predict_pcr, c_test_pcr))\n",
    "\n",
    "print('Linear Discriminant Analysis (LDA)')\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, f_train_pcr, c_train_pcr, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the size of training dataset to build a better model\n",
    "f_train_vcr, f_test_vcr, c_train_vcr, c_test_vcr = train_test_split(Charlotte_11_15_data_imputed_most_frequent.loc[:, ['NPA', \n",
    "    'Vacant_Land', 'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_most_frequent.loc[:,['Violent_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "f_train_pcr, f_test_pcr, c_train_pcr, c_test_pcr = train_test_split(Charlotte_11_15_data_imputed_most_frequent.loc[:, ['NPA', \n",
    "    'Vacant_Land', 'Vacant_Land_Area', 'Commercial_Construction', 'Commercial_Construction_Permitted_Units', 'Commercial_Size', \n",
    "    'Commercial_Size_Total', 'Commercial_Building_Age', 'Impervious_Surface', 'Impervious_Surface_Area', 'Adopt_a_Stream', \n",
    "    'Adopt_a_Stream_Length', 'Pharmacy_Proximity', 'Pharmacy_Proximate_Units', 'Housing_Density', 'Housing_Units', \n",
    "    'Single_Family_Housing', 'Single_Family_Units', 'Housing_Size', 'Housing_Age', 'New_Residential', 'New_Residential_Permit_Units', \n",
    "    'Residential_Renovation', 'Residential_Renovation_Permit_Units', 'Foreclosures', 'Foreclosed_Units', 'Housing_Violations', \n",
    "    'Housing_Violations_Total', 'Street_Connectivity', 'Transit_Proximity', 'Transit_Proximate_Units']], \n",
    "    Charlotte_11_15_data_imputed_most_frequent.loc[:,['Property_Crime_Rate_Class']], test_size=0.01, train_size = 0.99, shuffle=True)\n",
    "\n",
    "# predict crime rate besed on best classifier from above\n",
    "c_predict_vcr = KNeighborsClassifier().fit(f_train_vcr, c_train_vcr).predict(Charlotte_16_data_imputed_most_frequent)\n",
    "c_predict_pcr = KNeighborsClassifier().fit(f_train_pcr, c_train_pcr).predict(Charlotte_16_data_imputed_most_frequent)\n",
    "\n",
    "Charlotte_16_data_write2csv = Charlotte_16_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Charlotte_16_data_write2csv['Violent_Crime_Rate'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Combined_Crime_Rate'] = 0.0\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Log2'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Log2'] = c_predict_pcr\n",
    "\n",
    "Charlotte_16_data_write2csv['Violent_Crime_Rate_Class'] = c_predict_vcr\n",
    "Charlotte_16_data_write2csv['Property_Crime_Rate_Class'] = c_predict_pcr\n",
    "\n",
    "for index, row in Charlotte_16_data_write2csv.iterrows():\n",
    "    Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Class'] * interval_vcr\n",
    "    Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate_Log2'], 2.0)\n",
    "        \n",
    "    Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'] = Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Class'] * interval_vcr\n",
    "    Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate'] = pow(Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate_Log2'], 2.0)\n",
    "    \n",
    "    Charlotte_16_data_write2csv.at[index, 'Combined_Crime_Rate'] = (Charlotte_16_data_write2csv.at[index, 'Violent_Crime_Rate'] + Charlotte_16_data_write2csv.at[index, 'Property_Crime_Rate']) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "Charlotte_16_data_write2csv.to_csv(\"Datasets/Charlotte-Mecklenburg_2016_predict_MOST_FREQUENT.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar charts based on predicted data for 2016\n",
    "c_predict_2016_vcr = c_predict_vcr.astype(int)\n",
    "c_predict_2016_pcr = c_predict_pcr.astype(int)\n",
    "\n",
    "count_vcr_2016 = np.bincount(c_predict_2016_vcr)\n",
    "count_pcr_2016 = np.bincount(c_predict_2016_pcr)\n",
    "\n",
    "# print c_predict_2016_vcr\n",
    "# print c_predict_2016_pcr\n",
    "\n",
    "# Count # of class predictions \n",
    "count_class_0_vcr_2016 = count_vcr_2016[0]\n",
    "count_class_1_vcr_2016 = count_vcr_2016[1]\n",
    "count_class_2_vcr_2016 = count_vcr_2016[2]\n",
    "count_class_3_vcr_2016 = count_vcr_2016[3]\n",
    "\n",
    "count_class_0_pcr_2016 = count_pcr_2016[0]\n",
    "count_class_1_pcr_2016 = count_pcr_2016[1]\n",
    "count_class_2_pcr_2016 = count_pcr_2016[2]\n",
    "count_class_3_pcr_2016 = count_pcr_2016[3]\n",
    "\n",
    "# Define Classes Names\n",
    "#objects = (\"Class 0: \" + str(count_class_0_vcr_2016), 'Class 1', 'Class 2', 'Class 3')\n",
    "objects = ('Lower Crime', '', '', 'Higher Crime')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "# Plotting Violent Crime Data 2016\n",
    "performance = [count_class_0_vcr_2016, count_class_1_vcr_2016, count_class_2_vcr_2016, count_class_3_vcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Violent Crime')\n",
    "plt.title('Violent Crime Data 2016 - Most Frequent')\n",
    "plt.savefig('Barcharts/Violent_Crime_Data_2016_MOST_FREQUENT.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Property Crime Data 2016\n",
    "performance = [count_class_0_pcr_2016, count_class_1_pcr_2016, count_class_2_pcr_2016, count_class_3_pcr_2016]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Property Crime')\n",
    "plt.title('Property Crime Data 2016 - Most Frequent')\n",
    "plt.savefig('Barcharts/Property_Crime_Data_2016_MOST_FREQUENT.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
